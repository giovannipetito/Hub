{
  "1": {
    "inputs": {
      "text": "(low quality, worst quality:1.4),  text, signature, watermark, extra limbs, cleavage",
      "clip": [
        "3",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "3": {
    "inputs": {
      "ckpt_name": "sdxl\\dreamshaperXL_v21TurboDPMSDE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "4": {
    "inputs": {
      "image": [
        "21",
        0
      ]
    },
    "class_type": "DF_Get_image_size",
    "_meta": {
      "title": "Get image size"
    }
  },
  "6": {
    "inputs": {
      "preprocessor": "LineArtPreprocessor",
      "resolution": 512,
      "image": [
        "21",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "8": {
    "inputs": {
      "control_net_name": "sdxl\\controlnet-union-sdxl-1.0_promax.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "9": {
    "inputs": {
      "preprocessor": "DepthAnythingV2Preprocessor",
      "resolution": 512,
      "image": [
        "21",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "10": {
    "inputs": {
      "strength": 0.5,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "23",
        0
      ],
      "negative": [
        "1",
        0
      ],
      "control_net": [
        "8",
        0
      ],
      "image": [
        "9",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "11": {
    "inputs": {
      "strength": 0.25,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "10",
        0
      ],
      "negative": [
        "10",
        1
      ],
      "control_net": [
        "8",
        0
      ],
      "image": [
        "6",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "12": {
    "inputs": {
      "tile_size": 512,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "pixels": [
        "21",
        0
      ],
      "vae": [
        "3",
        2
      ]
    },
    "class_type": "VAEEncodeTiled",
    "_meta": {
      "title": "VAE Encode (Tiled)"
    }
  },
  "13": {
    "inputs": {
      "samples": [
        "12",
        0
      ],
      "mask": [
        "16",
        0
      ]
    },
    "class_type": "SetLatentNoiseMask",
    "_meta": {
      "title": "Set Latent Noise Mask"
    }
  },
  "14": {
    "inputs": {
      "seed": 626060053744533,
      "steps": 8,
      "cfg": 2,
      "sampler_name": "dpmpp_sde",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "3",
        0
      ],
      "positive": [
        "11",
        0
      ],
      "negative": [
        "11",
        1
      ],
      "latent_image": [
        "13",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "15": {
    "inputs": {
      "width": [
        "4",
        0
      ],
      "height": [
        "4",
        1
      ],
      "keep_proportions": true,
      "upscale_method": "nearest-exact",
      "crop": "disabled",
      "mask": [
        "24",
        0
      ]
    },
    "class_type": "ResizeMask",
    "_meta": {
      "title": "Resize Mask"
    }
  },
  "16": {
    "inputs": {
      "expand": 10,
      "incremental_expandrate": 0,
      "tapered_corners": true,
      "flip_input": false,
      "blur_radius": 4,
      "lerp_alpha": 1,
      "decay_factor": 1,
      "fill_holes": false,
      "mask": [
        "15",
        0
      ]
    },
    "class_type": "GrowMaskWithBlur",
    "_meta": {
      "title": "Grow Mask With Blur"
    }
  },
  "17": {
    "inputs": {
      "model": "sam2_hiera_large.safetensors",
      "segmentor": "single_image",
      "device": "cuda",
      "precision": "bf16"
    },
    "class_type": "DownloadAndLoadSAM2Model",
    "_meta": {
      "title": "(Down)Load SAM2Model"
    }
  },
  "18": {
    "inputs": {
      "model": "MiaoshouAI/Florence-2-large-PromptGen-v2.0",
      "precision": "fp16",
      "attention": "sdpa",
      "convert_to_safetensors": false
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "19": {
    "inputs": {
      "text_input": "hair",
      "task": "caption_to_phrase_grounding",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 3,
      "do_sample": true,
      "output_mask_select": "",
      "seed": 764576711434999,
      "image": [
        "21",
        0
      ],
      "florence2_model": [
        "18",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "20": {
    "inputs": {
      "index": "",
      "batch": false,
      "data": [
        "19",
        3
      ]
    },
    "class_type": "Florence2toCoordinates",
    "_meta": {
      "title": "Florence2 Coordinates"
    }
  },
  "21": {
    "inputs": {
      "upscale_method": "lanczos",
      "megapixels": 1,
      "image": [
        "22",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "22": {
    "inputs": {
      "image": "WhatsApp Image 2025-11-30 at 00.20.06.jpeg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "23": {
    "inputs": {
      "text": "multicolor hair",
      "clip": [
        "3",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "24": {
    "inputs": {
      "keep_model_loaded": true,
      "individual_objects": false,
      "sam2_model": [
        "17",
        0
      ],
      "image": [
        "19",
        0
      ],
      "bboxes": [
        "20",
        1
      ]
    },
    "class_type": "Sam2Segmentation",
    "_meta": {
      "title": "Sam2Segmentation"
    }
  },
  "25": {
    "inputs": {
      "tile_size": 512,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "samples": [
        "14",
        0
      ],
      "vae": [
        "3",
        2
      ]
    },
    "class_type": "VAEDecodeTiled",
    "_meta": {
      "title": "VAE Decode (Tiled)"
    }
  },
  "26": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "25",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  }
}